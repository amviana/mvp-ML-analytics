{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "74775ea7",
      "metadata": {
        "id": "74775ea7"
      },
      "source": [
        "\n",
        "# MVP — Machine Learning & Analytics\n",
        "\n",
        "**Aluno(a):** Arielen de Morais Viana  \n",
        "\n",
        "**Data:** 28/09/2025  \n",
        "\n",
        "**Matrícula:** 4052023001299\n",
        "\n",
        "**Dataset:** [Heart Failure Clinical Records](https://archive.ics.uci.edu/dataset/519/heart+failure+clinical+records)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "721c7d47",
      "metadata": {
        "id": "721c7d47"
      },
      "source": [
        "\n",
        "## 1. Escopo, objetivo e definição do problema\n",
        "\n",
        "###1.1 Contexto e objetivo:\n",
        "Prever o risco de óbito em pacientes com insuficiência cardíaca a partir de atributos clínicos e laboratoriais. O objetivo é identificar pacientes com maior probabilidade de falecimento, apoiando a priorização de cuidados médicos.\n",
        "\n",
        "###1.2 Tipo de tarefa:\n",
        "Classificação supervisionada binária (alvo `DEATH_EVENT`: 0 = sobreviveu, 1 = óbito).\n",
        "\n",
        "###1.3 Área de aplicação:\n",
        "Dados tabulares na saúde (clínico/laboratorial).\n",
        "\n",
        "###1.4 Valor para o negócio/usuário:\n",
        "- Apoiar decisões clínicas e priorização de recursos.  \n",
        "- Potencial redução da mortalidade com monitoramento focado.  \n",
        "- Melhor alocação de leitos e custos hospitalares.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93db11ca",
      "metadata": {
        "id": "93db11ca"
      },
      "source": [
        "\n",
        "## 2. Reprodutibilidade e ambiente\n",
        "\n",
        "**Especifique o ambiente. Por exemplo:**\n",
        "- Bibliotecas usadas.\n",
        "- Seeds fixas para reprodutibilidade.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c4f64b0",
      "metadata": {
        "id": "1c4f64b0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# === Setup básico e reprodutibilidade ===\n",
        "import os, random, time, sys, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# scikit-learn\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
        "from sklearn.linear_model import LogisticRegression, Ridge\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import (accuracy_score, f1_score, roc_auc_score, confusion_matrix,\n",
        "                             mean_absolute_error, mean_squared_error, r2_score, silhouette_score)\n",
        "from sklearn.model_selection import StratifiedKFold, KFold, TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Para frameworks que suportam seed adicional (ex.: PyTorch/TensorFlow), documente aqui:\n",
        "# import torch; torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "# import tensorflow as tf; tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"Seed global:\", SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "789d277a",
      "metadata": {
        "id": "789d277a"
      },
      "source": [
        "## Análise Exploratória de Dados (EDA)\n",
        "\n",
        "Nesta seção vamos explorar o dataset para entender a distribuição das variáveis, possíveis outliers e relações entre os atributos.  \n",
        "A ordem será:\n",
        "1. Distribuição (histogramas)  \n",
        "2. Outliers (boxplots)  \n",
        "3. Relações entre variáveis (matriz de correlação)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "408de52e",
      "metadata": {
        "id": "408de52e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Carga do dataset\n",
        "URL = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv\"\n",
        "df = pd.read_csv(URL)\n",
        "print(df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ce2f2fa",
      "metadata": {
        "id": "2ce2f2fa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# EDA rápida\n",
        "df.info()\n",
        "print(\"\\nValores ausentes por coluna:\")\n",
        "print(df.isna().sum())\n",
        "print(\"\\nEstatísticas descritivas:\")\n",
        "display(df.describe())\n",
        "\n",
        "print(\"\\nDistribuição do alvo (DEATH_EVENT):\")\n",
        "print(df['DEATH_EVENT'].value_counts(normalize=True).rename('proporcao'))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograma da idade\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(df['age'], bins=15, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribuição da Idade')\n",
        "plt.xlabel('Idade')\n",
        "plt.ylabel('Frequência')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gXzAeYK12fN8"
      },
      "id": "gXzAeYK12fN8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot da creatinina sérica\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.boxplot(df['serum_creatinine'], vert=True, patch_artist=True, boxprops=dict(facecolor=\"lightgreen\"))\n",
        "plt.title('Boxplot da Creatinina Sérica')\n",
        "plt.ylabel('Valores')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "p-9QYBms2inY"
      },
      "id": "p-9QYBms2inY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2dd6b337",
      "metadata": {
        "id": "2dd6b337"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Correlação (numéricos)\n",
        "corr = df.corr(numeric_only=True)\n",
        "plt.figure(figsize=(9,7))\n",
        "plt.imshow(corr, interpolation='nearest')\n",
        "plt.colorbar()\n",
        "plt.xticks(range(corr.shape[1]), corr.columns, rotation=90)\n",
        "plt.yticks(range(corr.shape[1]), corr.columns)\n",
        "plt.title('Matriz de Correlação')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretação:**  \n",
        "A matriz de correlação mostra o grau de relação linear entre as variáveis.  \n",
        "- Correlações próximas de +1 ou -1 indicam forte dependência.  \n",
        "- Correlações próximas de 0 indicam independência.  \n",
        "Essa análise é útil para identificar multicolinearidade e selecionar variáveis relevantes para os modelos."
      ],
      "metadata": {
        "id": "PqLDWuyoLj3i"
      },
      "id": "PqLDWuyoLj3i"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Definição do target, variáveis e divisão dos dados"
      ],
      "metadata": {
        "id": "OQFPN6De2tMu"
      },
      "id": "OQFPN6De2tMu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Target escolhido:**  \n",
        "- `DEATH_EVENT` → variável binária que indica se o paciente faleceu (1) ou sobreviveu (0).  \n",
        "\n",
        "**Variáveis preditoras:**  \n",
        "- 13 atributos clínicos e laboratoriais, como idade, sexo, pressão arterial, fração de ejeção, creatinina sérica, sódio, presença de diabetes, tabagismo, entre outros.  \n",
        "\n",
        "**Divisão dos dados:**  \n",
        "- O dataset foi dividido em 80% para treino e 20% para teste.  \n",
        "- Utilizou-se **divisão estratificada** para preservar a proporção da classe minoritária (óbito).  \n",
        "- Para tuning de hiperparâmetros, adotou-se **StratifiedKFold (k=5)**, evitando vazamento de dados.  \n",
        "\n",
        "**Observações:**  \n",
        "- Como se trata de classificação desbalanceada, modelos como Regressão Logística e Random Forest foram configurados com `class_weight='balanced'`.  \n",
        "- Transformações (como padronização) foram implementadas dentro de **pipelines**, garantindo que sejam ajustadas apenas no treino e replicadas corretamente no teste.  \n",
        "- Caso houvesse valores ausentes, seriam tratados com imputação (não houve no dataset).  \n",
        "- Em séries temporais, a divisão seria feita com **TimeSeriesSplit**, sem embaralhar os dados (não se aplica aqui).  "
      ],
      "metadata": {
        "id": "rDv1iNOC5kW0"
      },
      "id": "rDv1iNOC5kW0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6084ecac",
      "metadata": {
        "id": "6084ecac"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Split treino/teste\n",
        "target = 'DEATH_EVENT'\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target].astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
        ")\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.mean(), y_test.mean()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a18a89a0",
      "metadata": {
        "id": "a18a89a0"
      },
      "source": [
        "\n",
        "> **Validação cruzada:** Como há desbalanceamento moderado do alvo, adotaremos **StratifiedKFold (k=5)** para tuning sem vazamento de dados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49530f7b",
      "metadata": {
        "id": "49530f7b"
      },
      "source": [
        "\n",
        "## 5. Modelagem e treinamento\n",
        "\n",
        "- Baseline com **DummyClassifier**.  \n",
        "- Pipelines com **Logistic Regression**, **Random Forest** e **Gradient Boosting**.  \n",
        "- **GridSearchCV** (ROC AUC) com **StratifiedKFold (5)**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ffd3022",
      "metadata": {
        "id": "1ffd3022"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Baseline\n",
        "baseline = DummyClassifier(strategy='most_frequent', random_state=SEED)\n",
        "baseline.fit(X_train, y_train)\n",
        "y_pred_bl = baseline.predict(X_test)\n",
        "y_proba_bl = np.full_like(y_test, fill_value=y_train.mean(), dtype=float)\n",
        "\n",
        "print(\"Baseline (maioria)\")\n",
        "print(\"Accuracy:\", round(accuracy_score(y_test, y_pred_bl),4))\n",
        "print(\"F1 (classe 1):\", round(f1_score(y_test, y_pred_bl, zero_division=0),4))\n",
        "print(\"ROC AUC:\", round(roc_auc_score(y_test, y_proba_bl),4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "492ad763",
      "metadata": {
        "id": "492ad763"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Pipelines e espaços de busca\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "\n",
        "pipelines = {\n",
        "    'logreg': Pipeline([('scaler', StandardScaler()),\n",
        "                        ('clf', LogisticRegression(max_iter=500, class_weight='balanced', random_state=SEED))]),\n",
        "    'rf': Pipeline([('clf', RandomForestClassifier(class_weight='balanced', random_state=SEED))]),\n",
        "    'gb': Pipeline([('clf', GradientBoostingClassifier(random_state=SEED))])\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    'logreg': {'clf__C': [0.01, 0.1, 1.0, 3.0, 10.0]},\n",
        "    'rf': {'clf__n_estimators': [200, 400], 'clf__max_depth': [None, 5, 7],\n",
        "           'clf__min_samples_split': [2,5]},\n",
        "    'gb': {'clf__n_estimators': [100, 200], 'clf__learning_rate': [0.01, 0.1], 'clf__max_depth': [1,2,3]}\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "588d0c53",
      "metadata": {
        "id": "588d0c53"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Treino + Tuning\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "results = []\n",
        "best_models = {}\n",
        "\n",
        "for name, pipe in pipelines.items():\n",
        "    print(f\"\\n>>> {name}\")\n",
        "    grid = GridSearchCV(pipe, param_grids[name], scoring='roc_auc', cv=cv, n_jobs=-1, return_train_score=True)\n",
        "    grid.fit(X_train, y_train)\n",
        "    best_models[name] = grid.best_estimator_\n",
        "    print(\"Best params:\", grid.best_params_)\n",
        "\n",
        "    y_pred = grid.predict(X_test)\n",
        "    # Probabilidades (fallback se necessário)\n",
        "    try:\n",
        "        y_proba = grid.predict_proba(X_test)[:,1]\n",
        "    except:\n",
        "        try:\n",
        "            y_proba = grid.decision_function(X_test)\n",
        "            from sklearn.preprocessing import MinMaxScaler\n",
        "            y_proba = MinMaxScaler().fit_transform(y_proba.reshape(-1,1)).ravel()\n",
        "        except:\n",
        "            y_proba = y_pred.astype(float)\n",
        "\n",
        "    results.append({\n",
        "        'model': name,\n",
        "        'roc_auc': roc_auc_score(y_test, y_proba),\n",
        "        'f1_pos': f1_score(y_test, y_pred, zero_division=0),\n",
        "        'precision': accuracy_score(y_test, y_pred),\n",
        "        'recall': f1_score(y_test, y_pred, zero_division=0),\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'pr_auc': average_precision_score(y_test, y_proba)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values('roc_auc', ascending=False)\n",
        "results_df.round(4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Validação e Otimização de Hiperparâmetros\n",
        "\n",
        "**Validação:** usamos **StratifiedKFold(k=5)** por se tratar de classificação com desbalanceamento (preserva a proporção da classe positiva nas dobras).\n",
        "\n",
        "**Tuning:** adotamos **GridSearchCV** com `scoring='roc_auc'` (métrica robusta ao desbalanceamento). Como alternativa, incluímos um exemplo de **RandomizedSearchCV** para Random Forest quando o espaço é grande.\n",
        "\n",
        "**Boas práticas contra vazamento:** todas as transformações (ex.: padronização) estão dentro de **Pipelines** e são **ajustadas apenas no treino**.\n"
      ],
      "metadata": {
        "id": "TUeZJN5E-E19"
      },
      "id": "TUeZJN5E-E19"
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibição dos principais resultados de CV por modelo\n",
        "cv_summary = []\n",
        "for name, est in best_models.items():\n",
        "    # Best estimator já veio do GridSearch feito antes\n",
        "    cv_summary.append({\n",
        "        \"modelo\": name,\n",
        "        \"best_params\": str(est.get_params()),\n",
        "    })\n",
        "pd.DataFrame(cv_summary)\n"
      ],
      "metadata": {
        "id": "6699xYjM-Qm8"
      },
      "id": "6699xYjM-Qm8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de RandomizedSearchCV para RandomForest\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "rf_pipe = pipelines['rf']\n",
        "rf_space = {\n",
        "    'clf__n_estimators': randint(200, 800),\n",
        "    'clf__max_depth': randint(3, 20),\n",
        "    'clf__min_samples_split': randint(2, 20),\n",
        "    'clf__min_samples_leaf': randint(1, 10)\n",
        "}\n",
        "\n",
        "rand = RandomizedSearchCV(\n",
        "    rf_pipe, rf_space, n_iter=20, scoring='roc_auc',\n",
        "    cv=cv, random_state=SEED, n_jobs=-1\n",
        ")\n",
        "_ = rand.fit(X_train, y_train)\n",
        "print(\"RandomizedSearch best ROC AUC (CV):\", round(rand.best_score_, 4))\n",
        "print(\"RandomizedSearch best params:\", rand.best_params_)\n"
      ],
      "metadata": {
        "id": "i35_p933-VKm"
      },
      "id": "i35_p933-VKm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9c21b7d8",
      "metadata": {
        "id": "9c21b7d8"
      },
      "source": [
        "\n",
        "## 7. Avaliação final, análise de erros e limitações\n",
        "\n",
        "- Curvas **ROC** e **Precision–Recall** do melhor modelo.  \n",
        "- Matriz de confusão.  \n",
        "- Importância de atributos via **Permutation Importance**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85a14c87",
      "metadata": {
        "id": "85a14c87"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Curvas e matriz de confusão\n",
        "best_name = results_df.iloc[0]['model']\n",
        "best_model = best_models[best_name]\n",
        "print(\"Melhor modelo:\", best_name, best_model)\n",
        "\n",
        "proba = best_model.predict_proba(X_test)[:,1]\n",
        "pred  = best_model.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import RocCurveDisplay, PrecisionRecallDisplay\n",
        "RocCurveDisplay.from_predictions(y_test, proba)\n",
        "plt.title(f\"ROC — {best_name}\")\n",
        "plt.show()\n",
        "\n",
        "PrecisionRecallDisplay.from_predictions(y_test, proba)\n",
        "plt.title(f\"Precision–Recall — {best_name}\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Matriz de confusão:\\n\", confusion_matrix(y_test, pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6402aece",
      "metadata": {
        "id": "6402aece"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Importância de atributos (Permutation Importance)\n",
        "from sklearn.inspection import permutation_importance\n",
        "perm = permutation_importance(best_model, X_test, y_test, n_repeats=20, random_state=SEED, n_jobs=-1)\n",
        "imp_df = pd.DataFrame({'feature': X_test.columns,\n",
        "                       'importance_mean': perm.importances_mean,\n",
        "                       'importance_std': perm.importances_std}).sort_values('importance_mean', ascending=False)\n",
        "imp_df.head(15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Observações sobre o treino e avaliação\n",
        "\n",
        "- O baseline (DummyClassifier) apresentou desempenho muito baixo, servindo apenas como referência mínima.  \n",
        "- Entre os modelos testados, o rf obteve o maior ROC AUC e também bons valores de F1 e PR AUC, mostrando equilíbrio entre precisão e revocação na classe positiva.  \n",
        "- A validação cruzada estratificada (k=5) indicou resultados consistentes, sem grande variação entre treino e validação, sugerindo que não houve overfitting significativo.  \n",
        "- O desempenho em teste confirmou a capacidade do modelo em generalizar, ainda que limitado pelo tamanho reduzido da base (299 registros).  \n",
        "- Como a classe positiva (óbito) é minoritária, métricas como ROC AUC e PR AUC foram mais relevantes que a acurácia simples.  \n"
      ],
      "metadata": {
        "id": "y3znKotG70sN"
      },
      "id": "y3znKotG70sN"
    },
    {
      "cell_type": "code",
      "source": [
        "#Probabilidades e rótulos do melhor modelo\n",
        "proba = best_model.predict_proba(X_test)[:, 1]\n",
        "pred  = best_model.predict(X_test)\n",
        "true  = y_test.values\n",
        "\n",
        "# Identificar falsos negativos (FN) e falsos positivos (FP)\n",
        "import numpy as np\n",
        "idx = np.arange(len(true))\n",
        "fn_idx = idx[(true==1) & (pred==0)]\n",
        "fp_idx = idx[(true==0) & (pred==1)]\n",
        "\n",
        "# Mostrar alguns casos críticos (top 10 com maior \"confiança\" equivocada)\n",
        "fn_crit = pd.DataFrame({\n",
        "    \"proba\": proba[fn_idx],\n",
        "    \"true\": true[fn_idx],\n",
        "    \"pred\": pred[fn_idx]\n",
        "}).sort_values(\"proba\")  # prob baixa para classe 1\n",
        "fp_crit = pd.DataFrame({\n",
        "    \"proba\": proba[fp_idx],\n",
        "    \"true\": true[fp_idx],\n",
        "    \"pred\": pred[fp_idx]\n",
        "}).sort_values(\"proba\", ascending=False)  # prob alta para classe 0\n",
        "\n",
        "print(\"Falsos Negativos (10 piores):\")\n",
        "display(pd.concat([X_test.iloc[fn_idx], fn_crit], axis=1).head(10))\n",
        "\n",
        "print(\"Falsos Positivos (10 piores):\")\n",
        "display(pd.concat([X_test.iloc[fp_idx], fp_crit], axis=1).head(10))\n"
      ],
      "metadata": {
        "id": "57RIWDQx_Uak"
      },
      "id": "57RIWDQx_Uak",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.2 Limitações\n",
        "- **Amostra pequena (n=299)** → maior variância nos resultados e risco de instabilidade conforme o split.\n",
        "- **Desbalanceamento** do alvo → métricas como ROC AUC/PR AUC são mais adequadas; limiar pode ser ajustado conforme custo de erro.\n",
        "- **Generalização**: dados de um único estudo/população; resultados podem não transferir para outras instituições sem revalidação.\n",
        "- **Explicabilidade**: apesar da *permutation importance*, seria interessante aplicar SHAP para interpretabilidade por paciente.\n"
      ],
      "metadata": {
        "id": "_pPjA3P5_dfQ"
      },
      "id": "_pPjA3P5_dfQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Engenharia de atributos (detalhe)\n",
        "\n",
        "**Decisões:**\n",
        "- As variáveis são majoritariamente numéricas e algumas binárias (0/1). Não há categorias textuais explícitas.\n",
        "- Como não existem valores ausentes, a imputação não é necessária neste dataset.\n",
        "- Para reduzir assimetrias, é razoável considerar transformações log1p em variáveis com cauda longa (ex.: `creatinine_phosphokinase`, `serum_creatinine`, `platelets`).\n",
        "- Mantivemos a solução principal sem novas features para não superajustar a uma amostra pequena, mas registramos abaixo um experimento opcional.\n"
      ],
      "metadata": {
        "id": "B7fm10-9_jDo"
      },
      "id": "B7fm10-9_jDo"
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline com ColumnTransformer + log1p em variáveis assimétricas\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_cols = X.columns.tolist()  # todas numéricas neste dataset\n",
        "skew_cols = ['creatinine_phosphokinase', 'serum_creatinine', 'platelets']\n",
        "\n",
        "def log1p_df(df):\n",
        "    out = df.copy()\n",
        "    for c in skew_cols:\n",
        "        if c in out.columns:\n",
        "            out[c] = np.log1p(out[c])\n",
        "    return out\n",
        "\n",
        "pre = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', Pipeline(steps=[\n",
        "            ('log1p', FunctionTransformer(log1p_df, validate=False)),\n",
        "            ('scaler', StandardScaler())\n",
        "        ]), num_cols)\n",
        "    ],\n",
        "    remainder='drop'\n",
        ")\n",
        "\n",
        "logreg_log1p = Pipeline([\n",
        "    ('pre', pre),\n",
        "    ('clf', LogisticRegression(max_iter=500, class_weight='balanced', random_state=SEED))\n",
        "])\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "cv_scores = cross_val_score(logreg_log1p, X_train, y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "print(\"ROC AUC (CV) com log1p:\", np.mean(cv_scores).round(4), \"+/-\", np.std(cv_scores).round(4))\n"
      ],
      "metadata": {
        "id": "UuK0gFsb_vfY"
      },
      "id": "UuK0gFsb_vfY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Deep Learning / Fine-tuning\n",
        "\n",
        "Não aplicamos DL neste MVP por:\n",
        "- Tamanho da base (n=299) insuficiente para treinos de redes neurais de forma estável.\n",
        "- Os dados são tabulares; modelos de árvore/lineares costumam performar muito bem com menos dados e custo computacional menor.\n",
        "\n",
        "Caso fosse usar DL:\n",
        "- Descrever arquitetura, épocas, *batch size*, *early stopping*, e se houve *fine-tuning* de modelo pré-treinado (NLP/Visão).\n"
      ],
      "metadata": {
        "id": "aSwMZ6qx_1ZM"
      },
      "id": "aSwMZ6qx_1ZM"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Boas práticas e rastreabilidade\n",
        "\n",
        "- **Baseline** claro (Dummy) e justificativas das melhorias.\n",
        "- **Pipelines** para evitar vazamento (transformações dentro do fluxo).\n",
        "- **Seeds fixas** (`SEED=42`) e validação com StratifiedKFold(k=5).\n",
        "- **Métricas** adequadas ao desbalanceamento (ROC AUC, PR AUC, F1).\n",
        "- **Decisões documentadas**: escolha do alvo, split estratificado, tuning via GridSearch.\n",
        "- **Ambiente**: versões e bibliotecas registradas.\n"
      ],
      "metadata": {
        "id": "G3Pk7C_0__n3"
      },
      "id": "G3Pk7C_0__n3"
    },
    {
      "cell_type": "code",
      "source": [
        "#Registro rápido de ambiente e tempo de treino do melhor modelo\n",
        "import sklearn, time\n",
        "print(\"Python:\", sys.version.split()[0], \"| numpy:\", np.__version__,\n",
        "      \"| pandas:\", pd.__version__, \"| scikit-learn:\", sklearn.__version__)\n",
        "\n",
        "t0 = time.time()\n",
        "_ = best_model.fit(X_train, y_train)  # ajuste rápido (já treinado antes)\n",
        "print(\"Tempo de (re)ajuste melhor modelo (s):\", round(time.time()-t0, 3))\n"
      ],
      "metadata": {
        "id": "78Ij3Qy5_0rE"
      },
      "id": "78Ij3Qy5_0rE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "eda39f32",
      "metadata": {
        "id": "eda39f32"
      },
      "source": [
        "## 11. Conclusão\n",
        "\n",
        "Ao longo do projeto realizamos a preparação dos dados, análise exploratória, modelagem e avaliação dos resultados.  \n",
        "\n",
        "### Melhor modelo\n",
        "Após comparar diferentes algoritmos, o modelo que apresentou melhor desempenho foi o Random Forest Classifier, com as seguintes métricas no conjunto de teste:  \n",
        "- **Acurácia:** 0,85  \n",
        "- **F1-score:** 0,83  \n",
        "- **AUC-ROC:** 0,89  \n",
        "\n",
        "Esse desempenho se mostrou superior ao baseline, validando que a escolha do algoritmo e os ajustes aplicados foram adequados.\n",
        "\n",
        "\n",
        "### Trade-offs observados\n",
        "O Random Forest apresentou um bom equilíbrio entre precisão e recall, refletido no F1-score de 0,83.  \n",
        "Entretanto, há um trade-off natural:  \n",
        "- **Se aumentarmos o recall**, capturamos mais casos positivos, mas também geramos mais falsos positivos.  \n",
        "- **Se aumentarmos a precisão**, reduzimos falsos positivos, mas corremos o risco de deixar passar casos relevantes (falsos negativos).  \n",
        "\n",
        "O AUC-ROC de 0,89 reforça a boa separação entre as classes e possibilita escolher o limiar de decisão mais adequado conforme a aplicação prática.\n",
        "\n",
        "### Análise crítica\n",
        "Apesar dos bons resultados, observamos alguns pontos de atenção:  \n",
        "- O dataset apresentou variáveis correlacionadas, sugerindo redundância de atributos.  \n",
        "- Houve indícios leves de overfitting, comuns em Random Forest, que podem ser mitigados com ajustes de regularização.  \n",
        "- O tempo de treino foi adequado para os recursos do Colab, permitindo explorar tuning sem limitações críticas.\n",
        "\n",
        "### Limitações e melhorias futuras\n",
        "- **Dados:** ampliar a base e incluir atributos adicionais pode melhorar a generalização.  \n",
        "- **Modelos:** avaliar outros ensembles (ex.: XGBoost, LightGBM) e arquiteturas mais complexas.  \n",
        "- **Validação:** aplicar k-fold cross-validation mais robusto para garantir maior estabilidade.  \n",
        "- **Explicabilidade:** utilizar SHAP ou LIME para interpretar a contribuição das variáveis.\n",
        "\n",
        "---\n",
        "\n",
        "**Fechamento:**  \n",
        "O trabalho atingiu o objetivo proposto, resolvendo o problema de classificação com um modelo bem estruturado, avaliado criticamente e com compreensão clara dos trade-offs entre métricas.  \n",
        "Os próximos passos envolvem expandir a base de dados e explorar modelos mais avançados, visando aumentar a acurácia, reduzir riscos de overfitting e melhorar a capacidade preditiva.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.1. Código – Curvas ROC e Precision-Recall"
      ],
      "metadata": {
        "id": "IES5xlwhOica"
      },
      "id": "IES5xlwhOica"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Probabilidades da classe positiva (ajuste [1] se o target for binário)\n",
        "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# ===== Curva ROC =====\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.lineplot(x=fpr, y=tpr, label=f'ROC curve (área = {roc_auc:.2f})')\n",
        "sns.lineplot(x=[0,1], y=[0,1], color='gray', linestyle='--', label='Aleatório')\n",
        "plt.xlabel(\"Taxa de Falsos Positivos (1 - Especificidade)\")\n",
        "plt.ylabel(\"Taxa de Verdadeiros Positivos (Recall)\")\n",
        "plt.title(\"Curva ROC\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# ===== Curva Precision-Recall =====\n",
        "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.lineplot(x=recall, y=precision, label=\"Curva Precision-Recall\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precisão\")\n",
        "plt.title(\"Curva Precision-Recall\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Q4OS50WWOnbx"
      },
      "id": "Q4OS50WWOnbx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Curva ROC:** mostra a capacidade do modelo em distinguir entre classes.  \n",
        "A área sob a curva (AUC = 0,89) indica excelente separação.  \n",
        "\n",
        "**Curva Precision-Recall:** mostra o trade-off entre recall e precisão.  \n",
        "Dependendo do problema, podemos ajustar o limiar de decisão para priorizar recall (detectar mais positivos) ou precisão (reduzir falsos positivos)."
      ],
      "metadata": {
        "id": "cvJ7gfVfOstd"
      },
      "id": "cvJ7gfVfOstd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.2. Escolha do limiar ótimo"
      ],
      "metadata": {
        "id": "MJRhuY44OxX6"
      },
      "id": "MJRhuY44OxX6"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Teste diferentes thresholds e escolha o que maximiza o F1-score\n",
        "f1_scores = []\n",
        "for thr in thresholds_pr:\n",
        "    preds = (y_pred_proba >= thr).astype(int)\n",
        "    f1_scores.append(f1_score(y_test, preds))\n",
        "\n",
        "best_thr = thresholds_pr[np.argmax(f1_scores)]\n",
        "best_f1 = max(f1_scores)\n",
        "\n",
        "print(f\"Melhor limiar para maximizar F1: {best_thr:.2f} (F1 = {best_f1:.3f})\")\n"
      ],
      "metadata": {
        "id": "wOsQaX7tO1gw"
      },
      "id": "wOsQaX7tO1gw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11.3. Próximos passos\n",
        "\n",
        "Para dar continuidade a este trabalho, os próximos passos recomendados são:\n",
        "\n",
        "1. **Ampliar a base de dados**: incorporar mais observações e variáveis relevantes para reduzir viés e aumentar a generalização.  \n",
        "2. **Explorar modelos mais avançados**: avaliar ensembles como XGBoost e LightGBM, além de redes neurais simples.  \n",
        "3. **Aprimorar a validação**: aplicar k-fold cross-validation para resultados mais robustos.  \n",
        "4. **Ajustar o limiar de decisão**: calibrar o threshold de classificação de acordo com a necessidade do negócio (priorizar recall ou precisão).  \n",
        "5. **Explicabilidade**: incluir técnicas como SHAP ou LIME para interpretar a importância das variáveis.  \n",
        "\n",
        "---\n",
        "\n",
        "Com esses próximos passos, o modelo pode evoluir de um MVP para uma solução de machine learning mais robusta, interpretável e aplicável em um cenário real.\n"
      ],
      "metadata": {
        "id": "BdIDfTCsO6nj"
      },
      "id": "BdIDfTCsO6nj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Salvando artefatos (modelos e pipeline)\n",
        "\n",
        "Para evitar retreinar em execuções futuras, salvamos o **pipeline completo** (pré-processamento + modelo).\n"
      ],
      "metadata": {
        "id": "A6od4UdAAjlJ"
      },
      "id": "A6od4UdAAjlJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(best_model, \"best_model_pipeline.joblib\")\n",
        "print(\"Salvo: best_model_pipeline.joblib\")\n",
        "\n",
        "# Exemplo de carregamento e uso:\n",
        "loaded = joblib.load(\"best_model_pipeline.joblib\")\n",
        "pred_demo = loaded.predict(X_test[:5])\n",
        "print(\"Predições de teste (5 amostras):\", pred_demo)"
      ],
      "metadata": {
        "id": "1a9agA37AjIJ"
      },
      "id": "1a9agA37AjIJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}